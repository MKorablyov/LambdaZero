{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Model on Fingerprints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import corner\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from bayes_vs import bayes_models\n",
    "from bayes_vs import chem_ops\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ground-truth', 'cheap-docking_state_dict', 'expensive-docking_state_dict', 'FEP_state_dict'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt = torch.load('../scripts/trained_oracles.chkpt')\n",
    "chkpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220613"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chkpt['ground-truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(4184189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = rng.permutation(list(chkpt['ground-truth'].items()))\n",
    "smiles, values = zip(*shuffled)\n",
    "smiles = list(smiles)\n",
    "values = np.array(values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = 2500\n",
    "\n",
    "smiles_train, smiles_test = smiles[:-test_set_size], smiles[-test_set_size:]\n",
    "values_train, values_test = values[:-test_set_size], values[-test_set_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_on_data(smiles_train, smiles_test, y_train, y_test):\n",
    "    \n",
    "    out_rows = []\n",
    "    traing_set_size = len(smiles_train)\n",
    "    fps_train = np.stack([chem_ops.morgan_fp_from_smiles(smi) for smi in tqdm(smiles_train, desc='smiles fp train')]).astype(np.float32)\n",
    "    fps_test = np.stack([chem_ops.morgan_fp_from_smiles(smi) for smi in tqdm(smiles_test, desc='smiles fp test')]).astype(np.float32)\n",
    "    \n",
    "    bayes_embed = lambda x: x\n",
    "    bayes_embed.fp_dim = fps_train.shape[1]\n",
    "    \n",
    "    # Dummy Gaussian\n",
    "    mn = y_train.mean()\n",
    "    mse = np.mean((y_test-mn)**2)\n",
    "    ll = -0.5*np.mean(np.log(2*np.pi) + ((y_test-mn)**2))\n",
    "    out_rows.append(['Dummy Gaussian (var=1)', traing_set_size, f'{mse:.2f}', f'{ll:.2f}'])\n",
    "\n",
    "    # Linear regression with point estimate with weights\n",
    "    lin = linear_model.LinearRegression(fit_intercept=False)\n",
    "    lin.fit(fps_train, y_train)\n",
    "    predicted_mn = lin.predict(fps_test)\n",
    "    mse = np.mean((y_test-predicted_mn)**2)\n",
    "    ll = -0.5*np.mean(np.log(2*np.pi) + ((y_test-predicted_mn)**2))\n",
    "    out_rows.append(['Linear Regression/w Gaussian likelihood (var=1)', traing_set_size, f'{mse:.2f}', f'{ll:.2f}'])\n",
    "\n",
    "    \n",
    "    # Bayes regression\n",
    "    bayes_r = bayes_models.BayesianRegression(bayes_embed, False)\n",
    "    bayes_r.fit(torch.tensor(fps_train), torch.tensor(y_train[:, None]))\n",
    "    mvn = bayes_r.predict(torch.tensor(fps_test))\n",
    "    mse = np.mean((y_test-mvn.mean.detach().numpy())**2)\n",
    "    var = torch.diag(mvn.covariance_matrix)\n",
    "    ll =  -0.5 *torch.mean((torch.log(2*np.pi*var) + (torch.tensor(y_test)-mvn.mean)**2/var) )\n",
    "    ll = ll.item()\n",
    "    #pdb.set_trace()\n",
    "    #ll = mvn.log_prob(torch.tensor(y_test)).detach().numpy().mean()\n",
    "    out_rows.append(['Bayesian Regression', traing_set_size, f'{mse:.2f}', f'{ll:.2f}'])\n",
    "\n",
    "    \n",
    "    # Sklearn regression\n",
    "    clf = linear_model.BayesianRidge(compute_score=True, fit_intercept=False)\n",
    "    clf.fit(fps_train, y_train)\n",
    "    predicted_mn, predicted_std = clf.predict(fps_test,return_std=True)\n",
    "    ll = -0.5*np.mean(np.log(2*np.pi*predicted_std**2)  + ((y_test-predicted_mn)**2/predicted_std**2))\n",
    "    mse = np.mean((y_test-predicted_mn)**2)\n",
    "    out_rows.append(['Sklearn Bayesian Ridge Regression', traing_set_size, f'{mse:.2f}', f'{ll:.2f}'])\n",
    "\n",
    "    # Bayes Regression with sklearn params\n",
    "    bayes_r = bayes_models.BayesianRegression(bayes_embed, False)\n",
    "    bayes_r.alpha = clf.lambda_\n",
    "    bayes_r.beta = clf.alpha_\n",
    "    bayes_r.fit(torch.tensor(fps_train), torch.tensor(y_train[:, None]))\n",
    "    mvn = bayes_r.predict(torch.tensor(fps_test))\n",
    "    mse = np.mean((y_test-mvn.mean.detach().numpy())**2)\n",
    "    var = torch.diag(mvn.covariance_matrix)\n",
    "    ll =  -0.5 *torch.mean(torch.log(2*np.pi*var) + (torch.tensor(y_test)-mvn.mean)**2/var )\n",
    "    ll = ll.item()\n",
    "    out_rows.append([f'Bayesian Regression with the sklearn \\n learnt precisions (weights: {bayes_r.alpha:.3f},'\n",
    "                     f'noise:{bayes_r.beta:.3f})', traing_set_size, f'{mse:.2f}', f'{ll:.2f}'])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return out_rows\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smiles fp train: 100%|██████████| 10/10 [00:00<00:00, 1730.39it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2974.87it/s]\n",
      "smiles fp train: 100%|██████████| 20/20 [00:00<00:00, 3078.39it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 3010.34it/s]\n",
      "smiles fp train: 100%|██████████| 50/50 [00:00<00:00, 2565.20it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2984.23it/s]\n",
      "smiles fp train: 100%|██████████| 100/100 [00:00<00:00, 2439.78it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2953.69it/s]\n",
      "smiles fp train: 100%|██████████| 500/500 [00:00<00:00, 3010.76it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2781.53it/s]\n",
      "smiles fp train: 100%|██████████| 1000/1000 [00:00<00:00, 3107.73it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2975.65it/s]\n",
      "smiles fp train: 100%|██████████| 2500/2500 [00:00<00:00, 3002.88it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2976.96it/s]\n",
      "smiles fp train: 100%|██████████| 5000/5000 [00:01<00:00, 2578.61it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2700.34it/s]\n",
      "smiles fp train: 100%|██████████| 7500/7500 [00:02<00:00, 2890.43it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 3173.10it/s]\n",
      "smiles fp train: 100%|██████████| 10000/10000 [00:03<00:00, 2987.03it/s]\n",
      "smiles fp test: 100%|██████████| 2500/2500 [00:00<00:00, 2854.51it/s]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for train_size in [10, 20, 50, 100, 500, 1000, 2500, 5000, 7500, 10000]:\n",
    "    out.extend(test_on_data(smiles_train[:train_size], smiles_test, values_train[:train_size], values_test))\n",
    "    out.append([\"\"] * len(out[-1]))\n",
    "    out.append([\"\"] * len(out[-1]))\n",
    "    out.append([\"\"] * len(out[-1]))\n",
    "    out.append([\"---\"] * len(out[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                               Training set size    MSE (↓)    Avg Loglikelihood (↑)\n",
      "-------------------------------------------------  -------------------  ---------  -----------------------\n",
      "Dummy Gaussian (var=1)                             10                   23.69      -12.77\n",
      "Linear Regression/w Gaussian likelihood (var=1)    10                   21.74      -11.79\n",
      "Bayesian Regression                                10                   21.73      -3.01\n",
      "Sklearn Bayesian Ridge Regression                  10                   20.83      -3.03\n",
      "Bayesian Regression with the sklearn               10                   20.83      -2.95\n",
      " learnt precisions (weights: 7.076,noise:0.088)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             20                   21.05      -11.44\n",
      "Linear Regression/w Gaussian likelihood (var=1)    20                   19.98      -10.91\n",
      "Bayesian Regression                                20                   19.96      -2.97\n",
      "Sklearn Bayesian Ridge Regression                  20                   19.98      -1326.29\n",
      "Bayesian Regression with the sklearn               20                   19.98      -2.92\n",
      " learnt precisions (weights: 1.798,noise:148.416)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             50                   20.57      -11.20\n",
      "Linear Regression/w Gaussian likelihood (var=1)    50                   17.40      -9.62\n",
      "Bayesian Regression                                50                   17.37      -2.91\n",
      "Sklearn Bayesian Ridge Regression                  50                   19.79      -2.91\n",
      "Bayesian Regression with the sklearn               50                   19.79      -2.91\n",
      " learnt precisions (weights: 29.880,noise:0.049)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             100                  20.19      -11.01\n",
      "Linear Regression/w Gaussian likelihood (var=1)    100                  16.35      -9.09\n",
      "Bayesian Regression                                100                  16.25      -2.86\n",
      "Sklearn Bayesian Ridge Regression                  100                  16.19      -2.98\n",
      "Bayesian Regression with the sklearn               100                  16.19      -2.81\n",
      " learnt precisions (weights: 3.030,noise:0.149)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             500                  20.07      -10.95\n",
      "Linear Regression/w Gaussian likelihood (var=1)    500                  20.49      -11.16\n",
      "Bayesian Regression                                500                  17.69      -2.90\n",
      "Sklearn Bayesian Ridge Regression                  500                  12.72      -2.72\n",
      "Bayesian Regression with the sklearn               500                  12.72      -2.69\n",
      " learnt precisions (weights: 3.199,noise:0.149)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             1000                 20.10      -10.97\n",
      "Linear Regression/w Gaussian likelihood (var=1)    1000                 378.90     -190.37\n",
      "Bayesian Regression                                1000                 23.36      -4.16\n",
      "Sklearn Bayesian Ridge Regression                  1000                 11.70      -2.65\n",
      "Bayesian Regression with the sklearn               1000                 11.70      -2.65\n",
      " learnt precisions (weights: 3.830,noise:0.132)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             2500                 20.06      -10.95\n",
      "Linear Regression/w Gaussian likelihood (var=1)    2500                 15.88      -8.86\n",
      "Bayesian Regression                                2500                 14.97      -5.64\n",
      "Sklearn Bayesian Ridge Regression                  2500                 10.92      -2.61\n",
      "Bayesian Regression with the sklearn               2500                 10.92      -2.61\n",
      " learnt precisions (weights: 4.681,noise:0.115)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             5000                 20.02      -10.93\n",
      "Linear Regression/w Gaussian likelihood (var=1)    5000                 11.83      -6.83\n",
      "Bayesian Regression                                5000                 11.72      -5.67\n",
      "Sklearn Bayesian Ridge Regression                  5000                 10.38      -2.59\n",
      "Bayesian Regression with the sklearn               5000                 10.38      -2.59\n",
      " learnt precisions (weights: 5.729,noise:0.111)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             7500                 20.03      -10.93\n",
      "Linear Regression/w Gaussian likelihood (var=1)    7500                 10.87      -6.36\n",
      "Bayesian Regression                                7500                 10.84      -5.65\n",
      "Sklearn Bayesian Ridge Regression                  7500                 10.15      -2.58\n",
      "Bayesian Regression with the sklearn               7500                 10.15      -2.58\n",
      " learnt precisions (weights: 6.048,noise:0.111)\n",
      "---                                                ---                  ---        ---\n",
      "Dummy Gaussian (var=1)                             10000                20.03      -10.93\n",
      "Linear Regression/w Gaussian likelihood (var=1)    10000                10.51      -6.18\n",
      "Bayesian Regression                                10000                10.49      -5.66\n",
      "Sklearn Bayesian Ridge Regression                  10000                10.03      -2.57\n",
      "Bayesian Regression with the sklearn               10000                10.03      -2.57\n",
      " learnt precisions (weights: 6.215,noise:0.112)\n",
      "---                                                ---                  ---        ---\n"
     ]
    }
   ],
   "source": [
    "print(tabulate.tabulate(out, headers=['Name', \"Training set size\", \"MSE (↓)\", \"Avg Loglikelihood (↑)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
